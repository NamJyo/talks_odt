Recent years have seen a widespread adoption of machine learning in industry
and academia, impacting diverse areas from advertisement to personal medicine.
As more and more areas adopt machine learning and data science techniques, the
question arises on how much expertise is needed to successfully apply machine
learning, data science and statistics.  Not every company can afford a data
science team, and going your PhD in biology, no-one can expect you to have
PhD-level expertise in computer science and statistics.

This talk will summarize recent progress in automating machine learning and
give an overview of the tools currently available.  It will also point out
areas where the ecosystem needs to improve in order to allow a wider access to
inference using data science techniques.  Finally we will point out some open
problems regarding assumptions, and limitations of what can be automated.

The talk will first describe recent process in commodification of machine
learning, as witnessed by a wide array of open source packages and commercial
solutions.  Then I will discuss the setting of automating supervised learning,
and recent progress in automatic model selection and meta learning.

I will then examine three major limitations in this approach to automation: the
iid assumption, data representation, and the tension between predictive and
inferential modelling.

I will then go into more detail about how the problems of data representation
and inferential modelling might be solved by providing the user with richer
interfaces to interact with the data and the models, while the problem of the
iid assumption might require more intimate statistic knowledge on the side of
the user to overcome.
